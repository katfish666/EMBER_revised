{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://www.wavsource.com/snds_2020-10-01_3728627494378403/animals/cat_meow2.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import distance\n",
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "def allDone():\n",
    "    urL = 'https://www.wavsource.com/snds_2020-10-01_3728627494378403/animals/cat_meow2.wav'\n",
    "    display(Audio(url=urL, autoplay=True))\n",
    "allDone()\n",
    "\n",
    "random.seed(666)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 641\n"
     ]
    }
   ],
   "source": [
    "AMINOS = 'XWGSAELQDMPFTRIHVNCY_K'\n",
    "\n",
    "train_motifs = np.genfromtxt('data_dev/train_motifs.csv',dtype='U')\n",
    "train_motifxFamMatrix = np.genfromtxt('data_dev/train_motifxFamMatrix.csv',delimiter=',',\n",
    "                                      dtype=int)\n",
    "test_motifs = np.genfromtxt('data_dev/test_motifs.csv',dtype='U')\n",
    "test_motifxFamMatrix = np.genfromtxt('data_dev/test_motifxFamMatrix.csv',delimiter=',',\n",
    "                                     dtype=int)\n",
    "\n",
    "fams = np.genfromtxt('data_dev/fams.csv',dtype='U')\n",
    "\n",
    "all_motifs = np.hstack([train_motifs,test_motifs])\n",
    "all_motifxFamMatrix = np.vstack([train_motifxFamMatrix,test_motifxFamMatrix])\n",
    "\n",
    "X_train, X_val = train_test_split(range(len(train_motifs)), test_size=0.1, random_state=666)\n",
    "\n",
    "print(len(X_train), len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 22\n"
     ]
    }
   ],
   "source": [
    "gram_length = 1\n",
    "\n",
    "def get_gram_seq(motif,gram_length):\n",
    "    gram_seq = []\n",
    "    for i in range(len(motif)):\n",
    "        gram = motif[i:i+gram_length]\n",
    "        gram_seq.append(gram)\n",
    "    return gram_seq\n",
    "\n",
    "all_grams = []\n",
    "\n",
    "train_grammed_motifs = []\n",
    "for motif in train_motifs:\n",
    "    grammed_motif = get_gram_seq(motif,gram_length)\n",
    "    train_grammed_motifs.append(grammed_motif)\n",
    "    all_grams.extend(grammed_motif)\n",
    "    \n",
    "test_grammed_motifs = []\n",
    "for motif in test_motifs:\n",
    "    grammed_motif = get_gram_seq(motif,gram_length)\n",
    "    test_grammed_motifs.append(grammed_motif)\n",
    "    all_grams.extend(grammed_motif)\n",
    "    \n",
    "vocab_size = len(set(all_grams))\n",
    "print(\"vocab size:\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_motifs(grammed_motifs, all_grams):\n",
    "    gram_counts = Counter(all_grams)\n",
    "    gram_list = sorted(gram_counts, key=gram_counts.get, reverse=True)\n",
    "    gram_to_int = {gram:idx+1 for idx, gram in enumerate(gram_list)}  \n",
    "    encoded_motifs = [[gram_to_int[gram] for gram in motif] for motif in grammed_motifs]\n",
    "    return encoded_motifs, gram_to_int, gram_list\n",
    "\n",
    "train_encoded_motifs, gram_to_int, gram_list = get_encoded_motifs(train_grammed_motifs, \n",
    "                                                                  all_grams)\n",
    "test_encoded_motifs, gram_to_int, gram_list = get_encoded_motifs(test_grammed_motifs, \n",
    "                                                                 all_grams)\n",
    "\n",
    "all_encoded_motifs = train_encoded_motifs + test_encoded_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_motif_and_fam(idc):\n",
    "    mIdx = random.choice(idc)  \n",
    "    motif = train_encoded_motifs[mIdx] \n",
    "    fIdx = np.where(train_motifxFamMatrix[mIdx]==1)\n",
    "    theseFams = fams[fIdx]\n",
    "    return (mIdx,motif,fIdx,theseFams)\n",
    "\n",
    "def get_batch(idc,batch_size):\n",
    "    \n",
    "    batch = []\n",
    "    switch = 0\n",
    "    \n",
    "    while switch < batch_size:\n",
    "        mIdx_1, motif_1, fIdx_1, fams_1 = get_random_motif_and_fam(idc)\n",
    "        mIdx_2, motif_2, fIdx_2, fams_2 = get_random_motif_and_fam(idc)\n",
    "        \n",
    "        if len(fams_1)==0 and len(fams_2)==0: \n",
    "            continue\n",
    "        \n",
    "        label = distance.jaccard(set(fams_1),set(fams_2))\n",
    "        if switch%2 != round(label): #math.ceil(label):\n",
    "            continue\n",
    "        switch += 1\n",
    "            \n",
    "        triplet = [motif_1, motif_2, label]\n",
    "        batch.append(triplet)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "class SiameseLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, z1, z2, label, margin=2.0, dist_type='L2'):\n",
    "        ''' Calculates the pairwise loss given two embeddings and their 0/1 label.\n",
    "            margin: somewhere between 0.0 and 3.0\n",
    "            dist_type: manhattan (L1) or euclidean (L2)\n",
    "        '''\n",
    "        if dist_type=='L2':\n",
    "            distance = F.pairwise_distance(z1, z2)\n",
    "        elif dist_type=='L1':\n",
    "            distance = torch.sum( torch.abs(z1-z2), axis=1)\n",
    "        siam_loss = torch.mean((1-label) * torch.pow(distance, 2) +\n",
    "                                (label) * torch.pow(torch.clamp(margin - distance, \n",
    "                                                                min=0.0), 2))\n",
    "        return siam_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from siameseNet_CNN import Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "### Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size+1, embedding_dim=64)   \n",
    "        \n",
    "        self.lstm = nn.LSTM(64, 128, bidirectional=True,num_layers=2,\n",
    "                            batch_first=True,dropout=0.1)\n",
    "        \n",
    "#         self.lstm = nn.GRU(64, 128, bidirectional=True,num_layers=2,\n",
    "#                             batch_first=True,dropout=0.1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128*2*15, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.out = nn.Linear(512, 100)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.drpt = nn.Dropout(p=0.1)\n",
    "        \n",
    "        \n",
    "    def forward_once(self, motif): \n",
    "#         print(motif.shape)\n",
    "        \n",
    "        embedded = self.embedding(motif)\n",
    "#         print(embedded.shape)\n",
    "        lstmed, _ = self.lstm(embedded)\n",
    "        flattened = lstmed.reshape(lstmed.shape[0], lstmed.shape[1]*lstmed.shape[2])\n",
    "    \n",
    "#         print(flattened.shape)\n",
    "        fc1 = self.fc1(flattened)\n",
    "#         print(fc1.shape)\n",
    "        fc1 = self.relu(fc1)\n",
    "        fc1 = self.drpt(fc1)\n",
    "        \n",
    "        fc2 = self.fc2(fc1)\n",
    "#         print(fc2.shape)\n",
    "        fc2 = self.relu(fc2)\n",
    "        fc2 = self.drpt(fc2)\n",
    "        \n",
    "        fc3 = self.fc3(fc2)\n",
    "#         print(fc3.shape)\n",
    "        fc3 = self.relu(fc3)\n",
    "        fc3 = self.drpt(fc3)\n",
    "\n",
    "        out = self.out(fc3)\n",
    "#         print(out.shape)\n",
    "\n",
    "        return out\n",
    "        \n",
    "    def forward(self, motifs_net1, motifs_net2):\n",
    "        embed_1 = self.forward_once(motifs_net1)\n",
    "        embed_2 = self.forward_once(motifs_net2)\n",
    "        return (embed_1, embed_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, idc, optimizer, criterion, iters, batch_size, margin, dist_type):\n",
    "    \n",
    "    model.train()\n",
    "    loss_history = 0\n",
    "    \n",
    "    for i in range(iters):\n",
    "            \n",
    "        batch = get_batch(idc, batch_size)\n",
    "        motifs_net1 = torch.stack([torch.tensor(x[0]).to(device) for x in batch])\n",
    "        motifs_net2 = torch.stack([torch.tensor(x[1]).to(device) for x in batch])\n",
    "        labels = torch.stack([torch.tensor(x[2]).to(device) for x in batch])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        embeds_1, embeds_2 = model(motifs_net1, motifs_net2)\n",
    "        loss = criterion(embeds_1, embeds_2, labels, margin, dist_type)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        loss_history += loss.item()\n",
    "        \n",
    "    return loss_history / iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, idc, criterion, iters, batch_size, margin, dist_type):\n",
    "    \n",
    "    model.eval()\n",
    "    loss_history = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i in range(iters):\n",
    "            batch = get_batch(idc, batch_size)\n",
    "            motifs_net1 = torch.stack([torch.tensor(x[0]).to(device) for x in batch])\n",
    "            motifs_net2 = torch.stack([torch.tensor(x[1]).to(device) for x in batch])\n",
    "            labels = torch.stack([torch.tensor(x[2]).to(device) for x in batch])\n",
    "            \n",
    "            embeds_1, embeds_2 = model(motifs_net1, motifs_net2)\n",
    "            loss = criterion(embeds_1, embeds_2, labels,margin, dist_type)\n",
    "                \n",
    "            loss_history += loss.item()\n",
    "            \n",
    "    return loss_history / iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model() \n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.005 ) \n",
    "criterion = SiameseLoss()\n",
    "\n",
    "bs = 64\n",
    "\n",
    "# A sub_iter is a single fun through the network\n",
    "sub_iters = 100\n",
    "# Loss is calculated per super_iter (collection of sub_iters)\n",
    "super_iters = 50 \n",
    "\n",
    "my_margin = 1.5\n",
    "my_dist_type = 'L1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0 \n",
      "\n",
      "Time: 8.907 secs, Super iter 1\n",
      "* Train loss 9.9681 | Val loss: 0.6698\n",
      "Time: 7.831 secs, Super iter 2\n",
      "* Train loss 0.7908 | Val loss: 0.6761\n",
      "Time: 7.484 secs, Super iter 3\n",
      "* Train loss 0.6091 | Val loss: 0.5618\n",
      "Time: 6.902 secs, Super iter 4\n",
      "* Train loss 0.5213 | Val loss: 0.4650\n",
      "Time: 6.967 secs, Super iter 5\n",
      "* Train loss 0.4455 | Val loss: 0.4213\n",
      "Time: 7.008 secs, Super iter 6\n",
      "* Train loss 0.4343 | Val loss: 0.4604\n",
      "Time: 7.857 secs, Super iter 7\n",
      "* Train loss 0.4303 | Val loss: 0.3826\n",
      "Time: 6.973 secs, Super iter 8\n",
      "* Train loss 0.3998 | Val loss: 0.3783\n",
      "Time: 6.861 secs, Super iter 9\n",
      "* Train loss 0.3911 | Val loss: 0.3759\n",
      "Time: 7.332 secs, Super iter 10\n",
      "* Train loss 0.3888 | Val loss: 0.3473\n",
      "Time: 6.934 secs, Super iter 11\n",
      "* Train loss 0.3777 | Val loss: 0.3544\n",
      "Time: 6.993 secs, Super iter 12\n",
      "* Train loss 0.3636 | Val loss: 0.3544\n",
      "Time: 6.944 secs, Super iter 13\n",
      "* Train loss 0.3588 | Val loss: 0.3421\n",
      "Time: 6.902 secs, Super iter 14\n",
      "* Train loss 0.3444 | Val loss: 0.3573\n",
      "Time: 7.470 secs, Super iter 15\n",
      "* Train loss 0.3595 | Val loss: 0.3480\n",
      "Time: 7.508 secs, Super iter 16\n",
      "* Train loss 0.3699 | Val loss: 0.3664\n",
      "Time: 6.910 secs, Super iter 17\n",
      "* Train loss 0.3698 | Val loss: 0.3631\n",
      "Time: 6.881 secs, Super iter 18\n",
      "* Train loss 0.3643 | Val loss: 0.3562\n",
      "Time: 6.952 secs, Super iter 19\n",
      "* Train loss 0.3512 | Val loss: 0.3864\n",
      "Time: 6.912 secs, Super iter 20\n",
      "* Train loss 0.3462 | Val loss: 0.3725\n",
      "Time: 6.960 secs, Super iter 21\n",
      "* Train loss 0.3494 | Val loss: 0.3559\n"
     ]
    }
   ],
   "source": [
    "print(\"Device:\",device,\"\\n\")\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "best_val_loss = float('inf')\n",
    "total_time = time.time()\n",
    "\n",
    "best_super = 0\n",
    "for i in range(super_iters):\n",
    "    start = time.time()\n",
    "    train_loss = train(model, X_train, optimizer, criterion, \n",
    "                       iters=sub_iters, batch_size=bs, \n",
    "                       margin=my_margin, dist_type=my_dist_type)\n",
    "    val_loss = evaluate(model, X_val, criterion, \n",
    "                        iters=sub_iters, batch_size=bs,\n",
    "                        margin=my_margin, dist_type=my_dist_type)\n",
    "    \n",
    "    train_loss_history.append(train_loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "    \n",
    "    if val_loss <= best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_super = i\n",
    "\n",
    "    print(\"Time: %5.3f secs, Super iter %d\\n* Train loss %5.4f | Val loss: %5.4f\" % \n",
    "          ( time.time()-start, i+1, train_loss, val_loss ))\n",
    "\n",
    "final_model = Model().to(device)\n",
    "final_model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n--------------------Last super iter of learning:\",best_super)\n",
    "print(\"Total train time: %5.3f mins\" % ( (time.time()-total_time)/60 ))\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = '11'\n",
    "torch.save(model.state_dict(), \"MODELS_siam/siameseWeights_%s\" % run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model = Model().to(device)\n",
    "# model.load_state_dict(torch.load(\"MODELS_siam/siameseWeights_06\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(7.5,5))\n",
    "plt.plot(train_loss_history,label='train loss',c='blue')\n",
    "plt.plot(val_loss_history,label='val loss',c='red')\n",
    "plt.xlabel(\"super iteration\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"FIGS_siam/\" + run + \"_loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, enc_mots):\n",
    "    model.eval()\n",
    "    to_embed = torch.tensor(np.array((enc_mots))).to(device)\n",
    "    embedding = model.forward_once(to_embed)\n",
    "    return embedding.cpu().detach().numpy()\n",
    "\n",
    "embedded = get_embedding(model,all_encoded_motifs)   #range(len(motifs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embedded,dtype=float)\n",
    "df.to_csv(\"MODELS_siam/emb_%s_embedding.csv\" % (run),header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "umapper = umap.UMAP(\n",
    "    n_neighbors=20, # changed from 200\n",
    "    min_dist=0.5, # changed from 0.1\n",
    "    n_components=2,\n",
    "    metric='euclidean' )\n",
    "\n",
    "s = time.time()\n",
    "pos_umap = umapper.fit_transform(embedded)\n",
    "# allDone()\n",
    "\n",
    "print (\"secs: %5.3f\" % (time.time()-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "f = 'FIGS_siam/' + run + \"/\" \n",
    "os.mkdir(f)\n",
    "\n",
    "label_size = 45\n",
    "title_size = 50\n",
    "tick_size = 40\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "colors = ['red','#CD0000','deepskyblue','blue','green','blueviolet','orange','magenta','blueviolet','violet','deeppink','crimson','mediumslateblue','brown']\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.scatter(pos_umap[:, 0], pos_umap[:, 1], marker = 'o',s=5,color='black', alpha=1) #alpha=0.25)\n",
    "plt.title(\"Siamese latent space, UMAP reduction\",fontsize=title_size,y=1.01)\n",
    "plt.xlabel(\"UMAP-1\",fontsize=label_size)\n",
    "plt.ylabel(\"UMAP-2\",fontsize=label_size)\n",
    "plt.xticks(fontsize=tick_size)\n",
    "plt.yticks(fontsize=tick_size)\n",
    "\n",
    "plt.savefig( f + \"noHighlights\")\n",
    "plt.show()\n",
    "\n",
    "pop_fams = ['PKC', 'AKT', 'CDK', 'MAPK', 'SRC', 'CK2', 'PKA', 'PIKK']\n",
    "# pop_fams = ['CAMK-UNIQUE', 'DYRK', 'CAMKL', 'STE20', 'PKC', 'AKT', 'CDK', 'MAPK', 'SRC', 'CK2', 'PKA', 'PIKK']\n",
    "\n",
    "\n",
    "i = -1\n",
    "for _,fam in enumerate(pop_fams):\n",
    "    \n",
    "    i+=1\n",
    "    fIdx = np.where(fams==fam)[0][0]\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.title((\"Siamese latent space, UMAP reduction: %s\" % fam),fontsize=title_size,y=1.01)\n",
    "    plt.xticks(fontsize=tick_size)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "    plt.yticks(fontsize=tick_size)\n",
    "    plt.xlabel(\"UMAP-1\",fontsize=label_size)\n",
    "    plt.ylabel(\"UMAP-2\",fontsize=label_size)\n",
    "    plt.scatter(pos_umap[:, 0], pos_umap[:, 1], marker = 'o',s=25,color='grey',alpha=0.30)\n",
    "    for mIdx, (x, y) in enumerate(zip(pos_umap[:, 0], pos_umap[:, 1])):\n",
    "        if all_motifs[mIdx] not in test_motifs:\n",
    "            continue\n",
    "        elif all_motifxFamMatrix[mIdx][fIdx]==1:\n",
    "            plt.scatter(x,y,marker='o',s=200,c=colors[i],alpha=1.0,edgecolors='black')          \n",
    "    plt.savefig((f+\"%s\" % fam))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
